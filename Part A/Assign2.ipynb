{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e360e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1be854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_filters=32, size_filters=3, activation_func='relu', filter_org=1, num_dense=128, batch_normalisation=False, dropout_rate=0.2, input_channels=3, num_classes=10, num_conv=5):\n",
    "        '''\n",
    "        num_filters: Number of filters in each layer --> 32,64,etc\n",
    "        size_filters: Size of each filter (=F) --> 5,10,etc\n",
    "        activation_func: Activation function for the convolutional layers --> ReLU, GeLU,SiLU, Mish\n",
    "        filter_org: Ratio of number of filters in i+1th layer to number of filters in ith layer --> 1,0.5,2,etc\n",
    "        num_dense: Number of neurons in dense layer --> 128\n",
    "        batch_normalisation: Whether or not to apply batch normalisation after convolution layers --> True, False\n",
    "        dropout_rate: Fraction of neurons to randomly drop (=p) --> 0.2 to 0.5\n",
    "        input_channels: number of channels in input layer --> 3 (RGB)\n",
    "        num_classes: Number of Classes in the iNaturalist Dataset --> 10\n",
    "        num_conv: number of Conv-activation-maxpool blocks in the CNN model --> given:5\n",
    "        '''\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers=nn.ModuleList()\n",
    "\n",
    "        if activation_func == 'relu':\n",
    "            activation_layer = nn.ReLU()\n",
    "        elif activation_func == 'gelu':\n",
    "            activation_layer = nn.GELU()\n",
    "        elif activation_func == 'silu':\n",
    "            activation_layer = nn.SiLU()\n",
    "        elif activation_func == 'mish':\n",
    "            activation_layer = nn.Mish()\n",
    "\n",
    "        for layer in range(num_conv):\n",
    "            out_channels=int(num_filters*((filter_org)**(layer)))\n",
    "            self.layers.append(nn.Conv2d(in_channels=input_channels, out_channels=out_channels, kernel_size=size_filters, padding=size_filters//2))\n",
    "            if batch_normalisation==True:\n",
    "                self.layers.append(nn.BatchNorm(out_channels))\n",
    "            input_channels=out_channels\n",
    "            self.layers.append(activation_layer)                \n",
    "            self.layers.append(nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        if batch_normalisation==True:\n",
    "            self.fc_layers = nn.Sequential(nn.Linear(input_channels, num_dense),activation_layer, nn.BatchNorm1d(num_dense), nn.Dropout(p=dropout_rate), nn.Linear(num_dense, num_classes))\n",
    "        elif batch_normalisation==False:\n",
    "            self.fc_layers = nn.Sequential(nn.Linear(input_channels, num_dense),activation_layer, nn.Dropout(p=dropout_rate), nn.Linear(num_dense, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "from PIL import Image\n",
    "\n",
    "all_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dir = '/kaggle/input/inaturalist-10-class/train'\n",
    "class_names = sorted(os.listdir(dir))\n",
    "class_images = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_folder = os.path.join(dir, class_name)\n",
    "    first_image_path = os.path.join(class_folder, os.listdir(class_folder)[0])\n",
    "    image = Image.open(first_image_path)\n",
    "    image = all_transforms(image)\n",
    "    class_images.append(wandb.Image(image, caption=class_name))\n",
    "\n",
    "\n",
    "wandb.init(project=\"DA6401_Assign2\")\n",
    "wandb.log({\n",
    "    \"examples\": class_images\n",
    "})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(dir='/kaggle/input/inaturalist-10-class/train',augment='No',split=0.2,batch_size=64):\n",
    "    labels = datasets.ImageFolder(root=dir).targets\n",
    "    \n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    if augment=='Yes':\n",
    "        train_transforms = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
    "                                saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "        ])  \n",
    "    elif augment=='No':\n",
    "        train_transforms=val_transforms\n",
    "\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=split, random_state=42)\n",
    "    train_idx, val_idx = next(splitter.split(torch.zeros(len(labels)), labels))\n",
    "\n",
    "    train_dataset=datasets.ImageFolder(root=dir,transform=train_transforms)\n",
    "    val_dataset=datasets.ImageFolder(root=dir,transform=val_transforms)\n",
    "\n",
    "    train_dataset = Subset(train_dataset, train_idx)\n",
    "    val_dataset = Subset(val_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optim,lr,model):\n",
    "    if optim=='sgd':\n",
    "        return (torch.optim.SGD(model.parameters(), lr, weight_decay=0, momentum=0))\n",
    "    elif optim=='momentum':\n",
    "        return (torch.optim.SGD(model.parameters(), lr, weight_decay=0, momentum=0.9))\n",
    "    elif optim=='adam':\n",
    "        return (torch.optim.Adam(model.parameters(), lr, weight_decay=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e186948",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = CNN(\n",
    "    num_filters=32,\n",
    "    size_filters=3,\n",
    "    activation_func='relu',\n",
    "    filter_org=2,\n",
    "    num_dense=128\n",
    ").to(device)\n",
    "\n",
    "summary(my_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceead109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb.init(\n",
    "#     project=\"DA6401_Assign2\",\n",
    "# )\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'num_filters':{\n",
    "            'values':[32,64]\n",
    "        },\n",
    "        'size_filters':{\n",
    "            'values':[3,5,10]\n",
    "        },\n",
    "        'activation_func':{\n",
    "            'values':['relu','gelu','silu','mish']\n",
    "        },\n",
    "        'filter_org':{\n",
    "            'values':[1,0.5,2]\n",
    "        },\n",
    "        'num_dense':{\n",
    "            'values':[128,256,512]\n",
    "        },\n",
    "        'batch_size':{\n",
    "            'values':[16,32,64]\n",
    "        },\n",
    "        'optimizer':{\n",
    "            'values':['sgd','momentum','adam']\n",
    "        },\n",
    "        'learning_rate':{\n",
    "            'min':0.0001,\n",
    "            'max':0.01\n",
    "        },\n",
    "        'data_augmentation':{\n",
    "            'values':['Yes','No']\n",
    "        },\n",
    "        'batch_normalisation':{\n",
    "            'values':[True,False]\n",
    "        },\n",
    "        'dropout_rate':{\n",
    "            'min':0.2,\n",
    "            'max':0.5\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assign2\", entity=\"ishita49-indian-institute-of-technology-madras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config_defaults = {\n",
    "        'num_filters':32,\n",
    "        'size_filters':3,\n",
    "        'activation_func':'relu',\n",
    "        'filter_org':2,\n",
    "        'num_dense':128,\n",
    "        'batch_size':64,\n",
    "        'optimizer':'sgd',\n",
    "        'learning_rate':0.005,\n",
    "        'data_augmentation':'No',\n",
    "        'batch_normalisation':False,\n",
    "        'dropout_rate':0.2\n",
    "    }\n",
    "    \n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "\n",
    "    model = CNN(num_filters=config.num_filters,\n",
    "                size_filters=config.size_filters,\n",
    "                activation_func=config.activation_func,\n",
    "                filter_org=config.filter_org,\n",
    "                num_dense=config.num_dense,\n",
    "                batch_normalisation=config.batch_normalisation,\n",
    "                dropout_rate=config.dropout_rate,\n",
    "                num_classes=10)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer=get_optimizer(optim=config.optimizer,lr=config.learning_rate,model=model)\n",
    "    train_loader,val_loader=get_dataloaders(batch_size=config.batch_size,augment=config.data_augmentation)\n",
    "    # Train\n",
    "    num_epochs=20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss=0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=loss.item()\n",
    "        avg_loss=total_loss/len(train_loader)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, avg_loss))\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": avg_loss})\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Validation Accuracy: {:.2f}%'.format(accuracy))\n",
    "\n",
    "    wandb.log({\"val_accuracy\": accuracy})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "References={\n",
    "    \"CNN Model\":\"https://www.digitalocean.com/community/tutorials/writing-cnns-from-scratch-in-pytorch\",\n",
    "    \"Batch Normalisation\":\"https://datahacker.rs/017-pytorch-how-to-apply-batch-normalization-in-pytorch/\",\n",
    "    \"Dropout\":\"https://medium.com/@vishnuam/dropout-in-convolutional-neural-networks-cnn-422a4a17da41\"\n",
    " }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
