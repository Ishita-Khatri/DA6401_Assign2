{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d9be59",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41d1020e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T13:42:42.782944Z",
     "iopub.status.busy": "2025-04-18T13:42:42.782143Z",
     "iopub.status.idle": "2025-04-18T13:42:42.788465Z",
     "shell.execute_reply": "2025-04-18T13:42:42.787801Z",
     "shell.execute_reply.started": "2025-04-18T13:42:42.782919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import wandb\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb2603c",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3418e",
   "metadata": {},
   "source": [
    "## CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42edb036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:36:14.756316Z",
     "iopub.status.busy": "2025-04-18T12:36:14.756023Z",
     "iopub.status.idle": "2025-04-18T12:36:14.766409Z",
     "shell.execute_reply": "2025-04-18T12:36:14.765678Z",
     "shell.execute_reply.started": "2025-04-18T12:36:14.756292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_filters=32, size_filters=3, activation_func='relu', filter_org=1, num_dense=128, batch_normalisation=False, dropout_rate=0.2, input_channels=3, num_classes=10, num_conv=5):\n",
    "        '''\n",
    "        num_filters: Number of filters in each layer --> 32,64,etc\n",
    "        size_filters: Size of each filter (=F) --> 5,10,etc\n",
    "        activation_func: Activation function for the convolutional layers --> ReLU, GeLU,SiLU, Mish\n",
    "        filter_org: Ratio of number of filters in i+1th layer to number of filters in ith layer --> 1,0.5,2,etc\n",
    "        num_dense: Number of neurons in dense layer --> 128\n",
    "        batch_normalisation: Whether or not to apply batch normalisation after convolution layers --> True, False\n",
    "        dropout_rate: Fraction of neurons to randomly drop (=p) --> 0.2 to 0.5\n",
    "        input_channels: number of channels in input layer --> 3 (RGB)\n",
    "        num_classes: Number of Classes in the iNaturalist Dataset --> 10\n",
    "        num_conv: number of Conv-activation-maxpool blocks in the CNN model --> given:5\n",
    "        '''\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers=nn.ModuleList()\n",
    "\n",
    "        def get_activation(name):\n",
    "            if name == 'relu':\n",
    "                return nn.ReLU()\n",
    "            elif name == 'gelu':\n",
    "                return nn.GELU()\n",
    "            elif name == 'silu':\n",
    "                return nn.SiLU()\n",
    "            elif name == 'mish':\n",
    "                return nn.Mish()\n",
    "\n",
    "        for layer in range(num_conv):\n",
    "            out_channels=int(num_filters*((filter_org)**(layer)))\n",
    "            self.layers.append(nn.Conv2d(in_channels=input_channels, out_channels=out_channels, kernel_size=size_filters, padding=size_filters//2))\n",
    "            if batch_normalisation==True:\n",
    "                self.layers.append(nn.BatchNorm2d(out_channels))\n",
    "            input_channels=out_channels\n",
    "            self.layers.append(get_activation(name=activation_func))    \n",
    "            self.layers.append(nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        if batch_normalisation==True:\n",
    "            self.fc_layers = nn.Sequential(nn.Linear(input_channels, num_dense),get_activation(name=activation_func), nn.BatchNorm1d(num_dense), nn.Dropout(p=dropout_rate), nn.Linear(num_dense, num_classes))\n",
    "        elif batch_normalisation==False:\n",
    "            self.fc_layers = nn.Sequential(nn.Linear(input_channels, num_dense),get_activation(name=activation_func), nn.Dropout(p=dropout_rate), nn.Linear(num_dense, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a22440",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e765a9ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:36:21.107534Z",
     "iopub.status.busy": "2025-04-18T12:36:21.106915Z",
     "iopub.status.idle": "2025-04-18T12:36:21.115562Z",
     "shell.execute_reply": "2025-04-18T12:36:21.114805Z",
     "shell.execute_reply.started": "2025-04-18T12:36:21.107506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(dir='/kaggle/input/nature-12k/inaturalist_12K/train',augment='No',split=0.2,batch_size=64):\n",
    "    labels = datasets.ImageFolder(root=dir).targets\n",
    "    \n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    if augment=='Yes':\n",
    "        train_transforms = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
    "                                saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "        ])  \n",
    "    elif augment=='No':\n",
    "        train_transforms=val_transforms\n",
    "\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=split, random_state=42)\n",
    "    train_idx, val_idx = next(splitter.split(torch.zeros(len(labels)), labels))\n",
    "\n",
    "    train_dataset=datasets.ImageFolder(root=dir,transform=train_transforms)\n",
    "    val_dataset=datasets.ImageFolder(root=dir,transform=val_transforms)\n",
    "\n",
    "    train_dataset = Subset(train_dataset, train_idx)\n",
    "    val_dataset = Subset(val_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader,val_loader\n",
    "\n",
    "def test_dataloader(dir='/kaggle/input/nature-12k/inaturalist_12K/val',batch_size=32):    \n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_dataset=datasets.ImageFolder(root=dir,transform=all_transforms)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b4695",
   "metadata": {},
   "source": [
    "## Validating correctness of data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b27c552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:36:26.044761Z",
     "iopub.status.busy": "2025-04-18T12:36:26.044142Z",
     "iopub.status.idle": "2025-04-18T12:36:26.048907Z",
     "shell.execute_reply": "2025-04-18T12:36:26.048199Z",
     "shell.execute_reply.started": "2025-04-18T12:36:26.044724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_class_counts(dataloader):\n",
    "    dataset = dataloader.dataset\n",
    "    targets = [dataset.dataset.targets[i] for i in dataset.indices]\n",
    "    total=0\n",
    "    for cls,count in sorted(Counter(targets).items()):\n",
    "        print(f'Class{cls}: {count} samples')\n",
    "        total+=count\n",
    "    print(f'total samples={total}')\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431716a",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a5c652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:36:29.480385Z",
     "iopub.status.busy": "2025-04-18T12:36:29.479724Z",
     "iopub.status.idle": "2025-04-18T12:36:29.485162Z",
     "shell.execute_reply": "2025-04-18T12:36:29.484331Z",
     "shell.execute_reply.started": "2025-04-18T12:36:29.480357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(optim,lr,model):\n",
    "    if optim=='sgd':\n",
    "        return (torch.optim.SGD(model.parameters(), lr, weight_decay=0, momentum=0))\n",
    "    elif optim=='momentum':\n",
    "        return (torch.optim.SGD(model.parameters(), lr, weight_decay=0, momentum=0.9))\n",
    "    elif optim=='adam':\n",
    "        return (torch.optim.Adam(model.parameters(), lr, weight_decay=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1585915",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650238db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:41:02.298509Z",
     "iopub.status.busy": "2025-04-18T12:41:02.297655Z",
     "iopub.status.idle": "2025-04-18T12:41:20.736378Z",
     "shell.execute_reply": "2025-04-18T12:41:20.735555Z",
     "shell.execute_reply.started": "2025-04-18T12:41:02.298480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]          36,928\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-12           [-1, 64, 28, 28]               0\n",
      "           Conv2d-13           [-1, 64, 28, 28]          36,928\n",
      "      BatchNorm2d-14           [-1, 64, 28, 28]             128\n",
      "             ReLU-15           [-1, 64, 28, 28]               0\n",
      "        MaxPool2d-16           [-1, 64, 14, 14]               0\n",
      "           Conv2d-17           [-1, 64, 14, 14]          36,928\n",
      "      BatchNorm2d-18           [-1, 64, 14, 14]             128\n",
      "             ReLU-19           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-20             [-1, 64, 7, 7]               0\n",
      "AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0\n",
      "           Linear-22                  [-1, 256]          16,640\n",
      "             ReLU-23                  [-1, 256]               0\n",
      "      BatchNorm1d-24                  [-1, 256]             512\n",
      "          Dropout-25                  [-1, 256]               0\n",
      "           Linear-26                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 169,866\n",
      "Trainable params: 169,866\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 106.07\n",
      "Params size (MB): 0.65\n",
      "Estimated Total Size (MB): 107.29\n",
      "----------------------------------------------------------------\n",
      "Using 2 GPUs\n",
      "\n",
      "No. of samples in each class in training data:\n",
      "Class0: 800 samples\n",
      "Class1: 800 samples\n",
      "Class2: 800 samples\n",
      "Class3: 800 samples\n",
      "Class4: 799 samples\n",
      "Class5: 800 samples\n",
      "Class6: 800 samples\n",
      "Class7: 800 samples\n",
      "Class8: 800 samples\n",
      "Class9: 800 samples\n",
      "total samples=7999\n",
      "\n",
      "No. of samples in each class in Validation data:\n",
      "Class0: 200 samples\n",
      "Class1: 200 samples\n",
      "Class2: 200 samples\n",
      "Class3: 200 samples\n",
      "Class4: 200 samples\n",
      "Class5: 200 samples\n",
      "Class6: 200 samples\n",
      "Class7: 200 samples\n",
      "Class8: 200 samples\n",
      "Class9: 200 samples\n",
      "total samples=2000\n",
      "\n",
      "Percentage of train data kept aside for validation=20.00%\n"
     ]
    }
   ],
   "source": [
    "# Parameters of the Best Model\n",
    "# Validation Accuracy = 40.4%\n",
    "activation_func= 'relu'\n",
    "batch_normalisation=True\n",
    "batch_size=32\n",
    "data_augmentation='No'\n",
    "dropout_rate=0.20426922413644705\n",
    "filter_org=1\n",
    "learning_rate=0.0032148335356218384\n",
    "num_dense=256\n",
    "num_filters=64\n",
    "optimizer='momentum'\n",
    "size_filters=3\n",
    "\n",
    "model=CNN(num_filters, size_filters, activation_func, filter_org, num_dense, batch_normalisation, dropout_rate, input_channels=3, num_classes=10, num_conv=5)\n",
    "summary(model,input_size=(3,224,224),device='cpu')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer=get_optimizer(optimizer,learning_rate,model=model)\n",
    "train_loader,val_loader=get_dataloaders('/kaggle/input/nature-12k/inaturalist_12K/train',data_augmentation,0.2,batch_size)\n",
    "\n",
    "print('\\nNo. of samples in each class in training data:')\n",
    "train_count = get_class_counts(train_loader)\n",
    "print('\\nNo. of samples in each class in Validation data:')\n",
    "val_count = get_class_counts(val_loader)\n",
    "\n",
    "print('\\nPercentage of train data kept aside for validation={:.2f}%'.format(val_count*100/(train_count+val_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d78fe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T12:44:55.446149Z",
     "iopub.status.busy": "2025-04-18T12:44:55.445815Z",
     "iopub.status.idle": "2025-04-18T13:23:18.949006Z",
     "shell.execute_reply": "2025-04-18T13:23:18.948061Z",
     "shell.execute_reply.started": "2025-04-18T12:44:55.446122Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 2.1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 24.05%\n",
      "Validation Accuracy: 23.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 2.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 26.10%\n",
      "Validation Accuracy: 27.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 2.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 28.32%\n",
      "Validation Accuracy: 27.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 2.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 30.12%\n",
      "Validation Accuracy: 29.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 1.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 31.58%\n",
      "Validation Accuracy: 30.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 1.9635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 30.57%\n",
      "Validation Accuracy: 28.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 1.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 32.57%\n",
      "Validation Accuracy: 32.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 1.9089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 35.53%\n",
      "Validation Accuracy: 33.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 1.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 31.35%\n",
      "Validation Accuracy: 28.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 1.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 37.54%\n",
      "Validation Accuracy: 34.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 1.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 34.05%\n",
      "Validation Accuracy: 33.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 1.8317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 35.20%\n",
      "Validation Accuracy: 33.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 1.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 36.49%\n",
      "Validation Accuracy: 34.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 1.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 39.63%\n",
      "Validation Accuracy: 38.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 1.7972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 36.89%\n",
      "Validation Accuracy: 34.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 1.7719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 39.43%\n",
      "Validation Accuracy: 36.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 1.7653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 38.90%\n",
      "Validation Accuracy: 35.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 1.7439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 42.04%\n",
      "Validation Accuracy: 37.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 1.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 43.37%\n",
      "Validation Accuracy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 1.7178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 42.37%\n",
      "Validation Accuracy: 36.75%\n",
      "Test Accuracy: 36.40%\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_epochs=20\n",
    "print(\"training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "    avg_loss=total_loss/len(train_loader)\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, avg_loss))\n",
    "\n",
    "    # Validation on training data\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Train Accuracy: {:.2f}%'.format(accuracy))\n",
    "\n",
    "    # Validation on validation data\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Validation Accuracy: {:.2f}%'.format(accuracy))\n",
    "\n",
    "test_loader=test_dataloader(batch_size=32)\n",
    "# Test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Test Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761dd245",
   "metadata": {},
   "source": [
    "## Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86acd323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T13:45:17.246909Z",
     "iopub.status.busy": "2025-04-18T13:45:17.246260Z",
     "iopub.status.idle": "2025-04-18T13:45:17.251890Z",
     "shell.execute_reply": "2025-04-18T13:45:17.251306Z",
     "shell.execute_reply.started": "2025-04-18T13:45:17.246882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_images(dir=\"/kaggle/input/nature-12k/inaturalist_12K/val\"):\n",
    "    class_images = {}\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    for class_name in os.listdir(dir):\n",
    "        class_path = os.path.join(dir, class_name)\n",
    "        images = [f for f in os.listdir(class_path)]\n",
    "        img_path = os.path.join(class_path, random.choice(images))\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = all_transforms(img)\n",
    "        class_images[class_name] = img_tensor\n",
    "    return class_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec3bcff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T13:46:35.283124Z",
     "iopub.status.busy": "2025-04-18T13:46:35.282752Z",
     "iopub.status.idle": "2025-04-18T13:46:43.455252Z",
     "shell.execute_reply": "2025-04-18T13:46:43.454459Z",
     "shell.execute_reply.started": "2025-04-18T13:46:35.283102Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_134635-ybvcz4dh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2/runs/ybvcz4dh' target=\"_blank\">snowy-totem-75</a></strong> to <a href='https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2' target=\"_blank\">https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2/runs/ybvcz4dh' target=\"_blank\">https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2/runs/ybvcz4dh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">snowy-totem-75</strong> at: <a href='https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2/runs/ybvcz4dh' target=\"_blank\">https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2/runs/ybvcz4dh</a><br> View project at: <a href='https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2' target=\"_blank\">https://wandb.ai/ishita49-indian-institute-of-technology-madras/DA6401_Assign2</a><br>Synced 5 W&B file(s), 1 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250418_134635-ybvcz4dh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"DA6401_Assign2\")\n",
    "table = wandb.Table(columns=[\"Test Image\", \"True Label\", \"Predicted Label\"])\n",
    "class_images = get_images()\n",
    "model.eval()\n",
    "labels = datasets.ImageFolder('/kaggle/input/nature-12k/inaturalist_12K/val').classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    for class_name, img_tensor in class_images.items():\n",
    "        image = img_tensor.unsqueeze(0).to(device)\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_class = labels[predicted.item()]\n",
    "\n",
    "        img_disp = img_tensor.clone().detach().cpu()\n",
    "        img_disp = img_disp * torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "        img_disp = img_disp + torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "        img_disp = img_disp.clamp(0, 1)\n",
    "        table.add_data(wandb.Image(img_disp),class_name, predicted_class)\n",
    "\n",
    "wandb.log({\"10x3_grid\": table})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7121085,
     "sourceId": 11374628,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
